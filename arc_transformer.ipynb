{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.train import ARCModelState, ARCTrainParams\n",
    "from arc_prize.vis import visualize_epochs\n",
    "import modal\n",
    "import torch\n",
    "import petname\n",
    "from arc_prize.model import ARCTransformerEncoderDecoderParams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name fully_secure_fly fc-01J5NK97HAS61E47JJAEGZ02NZ\n",
      "['fully_secure_fly']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_params = ARCTransformerEncoderDecoderParams(\n",
    "  grid_dim=30,\n",
    "  num_train_pairs=10,\n",
    "  num_colors=10,\n",
    "  num_encoder_layers=2,\n",
    "  num_decoder_layers=2,\n",
    "  num_heads=4,\n",
    "  d_model=32,\n",
    "  d_ff=32*2,\n",
    "  dropout=0.2\n",
    ")\n",
    "\n",
    "train_params = ARCTrainParams(\n",
    "  batch_size=5,\n",
    "  learning_rate=1e-3,\n",
    "  weight_decay=1e-4,\n",
    "  dataset_dir=[\"/vol/data/arc\"],\n",
    "  loss_class_weights={0: 0.2}\n",
    ")\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "model_names = []\n",
    "\n",
    "num_runs = 1\n",
    "\n",
    "fn = modal.Function.lookup(\"arc-prize\", \"train\")\n",
    "for i in range(num_runs):\n",
    "  model_name = petname.generate(words=3, separator='_')\n",
    "  fn_call = fn.spawn(model_name, num_epochs, model_params, train_params)\n",
    "  # train_on_mac(model_name, num_epochs, model_params, train_params)\n",
    "  print(\"Model name\", model_name, fn_call.object_id)\n",
    "  model_names.append(model_name)\n",
    "\n",
    "print(model_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from arc_prize.model import ARCTransformerEncoderDecoderParams\n",
    "from arc_prize.train import train_on_mac\n",
    "\n",
    "\n",
    "model_params = ARCTransformerEncoderDecoderParams(\n",
    "  grid_dim=20,\n",
    "  num_train_pairs=4,\n",
    "  num_colors=10,\n",
    "  num_encoder_layers=2,\n",
    "  num_decoder_layers=2,\n",
    "  num_heads=4,\n",
    "  d_model=32,\n",
    "  d_ff=32*2,\n",
    "  dropout=0.2\n",
    ")\n",
    "\n",
    "train_params = ARCTrainParams(\n",
    "  batch_size=10,\n",
    "  learning_rate=1e-3,\n",
    "  weight_decay=1e-4,\n",
    "  dataset_dir=[\"data/move_diagonal\"]\n",
    ")\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "model_names = []\n",
    "\n",
    "num_runs = 3\n",
    "\n",
    "# fn = modal.Function.lookup(\"arc-prize\", \"train\")\n",
    "for i in range(num_runs):\n",
    "  model_name = petname.generate(words=3, separator='_')\n",
    "  # fn_call = fn.spawn(model_name, num_epochs, model_params, train_params)\n",
    "  train_on_mac(model_name, num_epochs, model_params, train_params)\n",
    "  # print(\"Model name\", model_name, fn_call.object_id)\n",
    "  model_names.append(model_name)\n",
    "\n",
    "print(model_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "model_names = [\"fully_solid_fly\"]\n",
    "\n",
    "fn = modal.Function.lookup(\"arc-prize\", \"train\")\n",
    "for model_name in model_names:\n",
    "  fn_call = fn.spawn(model_name, num_epochs, None, None)\n",
    "  print(\"Model name\", model_name, fn_call.object_id)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.vis import visualize_all_heads\n",
    "\n",
    "\n",
    "def visualize_group(model_names: list[str]):\n",
    "  epochs = {}\n",
    "  get_model = modal.Function.lookup(\"arc-prize\", \"get_model\")\n",
    "  for name in model_names:\n",
    "    checkpoint = ARCModelState(**get_model.remote(name))\n",
    "    print(name, len(checkpoint.epochs), checkpoint.epochs[-1], checkpoint.model_params)\n",
    "    epochs[name] = checkpoint.epochs\n",
    "\n",
    "\n",
    "    # print(len(checkpoint.encoder_attn_weights))\n",
    "    # for b, batch in enumerate(checkpoint.encoder_attn_weights):\n",
    "    #   for i, layer in enumerate(batch):\n",
    "    #     visualize_all_heads(layer, title=f\"Batch {b}, layer {i}\")\n",
    "    \n",
    "\n",
    "  visualize_epochs(epochs)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "groups = [\n",
    "  # ['kindly_huge_jennet', 'lovely_tidy_lab', 'solely_living_leech'], # BEST\n",
    "  # ['weekly_enough_moose', 'gently_known_beagle', 'nicely_robust_rhino'], # 20x20 too slow\n",
    "  # ['wildly_firm_husky', 'surely_brief_bug', 'fully_better_dodo'], # Amazing\n",
    "  # ['wildly_steady_iguana', 'yearly_smart_donkey', 'mainly_polite_bison'], # Includes scale dataset\n",
    "  # ['partly_vocal_piglet', 'neatly_needed_liger', 'firmly_game_weevil'], # Scale and diagonal\n",
    "  ['wholly_tops_heron', 'solely_eager_foal', 'deeply_one_skink'], # Tons of data\n",
    "  ['unduly_glad_swift', 'purely_steady_hornet', 'humbly_civil_donkey'], # Basic data\n",
    "]\n",
    "\n",
    "# print([group for sublist in groups for group in sublist])\n",
    "for group in groups:\n",
    "  visualize_group(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.vis import visualize_tensors, visualize_all_heads\n",
    "\n",
    "\n",
    "eval_model = modal.Function.lookup(\"arc-prize\", \"evaluate_model\")\n",
    "output = eval_model.remote(\"deeply_one_skink\", [\"/vol/data/move_diagonal_and_scale\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from arc_prize.vis import visualize_mean_mha_attention\n",
    "\n",
    "\n",
    "\n",
    "for item in output:\n",
    "  visualize_tensors(torch.Tensor(item[\"grids\"]).squeeze(0), torch.Tensor(item[\"output_grid\"]).squeeze(0), torch.Tensor(item[\"predictions\"]).squeeze(0))\n",
    "# print(torch.Tensor(item[\"decoder_sa_attn_weights\"]).shape)\n",
    "# for i, layer in enumerate(torch.Tensor(item[\"decoder_mha_attn_weights\"]).squeeze(0)):\n",
    "#   mean_attention = layer.mean(dim=1)\n",
    "#   print(mean_attention.shape)\n",
    "#   visualize_mean_mha_attention(layer)\n",
    "  # mean_attention = mean_attention.view(4, 9, 10, 10)\n",
    "  # print(mean_attention.shape)\n",
    "\n",
    "  # visualize_all_heads(layer, title=f\"Layer {i}\")\n",
    "# for i, layer in enumerate(torch.Tensor(item[\"decoder_sa_attn_weights\"]).squeeze(0)):\n",
    "#     visualize_mean_sa_attention(layer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.vis import visualize_output_query, visualize_tensors\n",
    "\n",
    "\n",
    "# model = ARCTransformer(d_model=d_model, num_heads=num_heads, num_layers=num_layers, d_ff=dim_feedforward, grid_dim=max_grid_size, num_colors=num_colors, num_train_pairs=max_context_pairs, dropout=dropout).to(device)\n",
    "\n",
    "model_file_name = \"models/model_75i3sirg.pth\"\n",
    "if model_file_name is not None:\n",
    "    state_dict = torch.load(model_file_name, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "eval_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, collate_fn=collate_arc_fn, num_workers=0)\n",
    "# batch = next(iter(eval_loader))\n",
    "\n",
    "# visualize_output_query(model.output_query)\n",
    "\n",
    "\n",
    "for i, batch in enumerate(eval_loader):\n",
    "    grids, grid_masks, output_grid = [item.to(device) for item in batch]\n",
    "\n",
    "    predictions = model.generate(grids, grid_masks)\n",
    "    print(predictions.shape)\n",
    "\n",
    "    visualize_tensors(grids.squeeze(0), output_grid.squeeze(0), predictions.squeeze(0))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
