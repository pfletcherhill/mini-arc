{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.model import ARCTransformerEncoderDecoderParams\n",
    "from arc_prize.train import ARCModelState, ARCTrainParams\n",
    "from arc_prize.vis import visualize_epochs\n",
    "import modal\n",
    "import torch\n",
    "import petname\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from arc_prize.train import train_on_mac\n",
    "\n",
    "\n",
    "model_params = ARCTransformerEncoderDecoderParams(\n",
    "  grid_dim=10,\n",
    "  num_train_pairs=4,\n",
    "  num_colors=10,\n",
    "  num_encoder_layers=2,\n",
    "  num_decoder_layers=2,\n",
    "  num_heads=2,\n",
    "  d_model=16,\n",
    "  d_ff=16*4,\n",
    "  dropout=0.1\n",
    ")\n",
    "\n",
    "train_params = ARCTrainParams(\n",
    "  batch_size=16,\n",
    "  learning_rate=3e-4,\n",
    "  weight_decay=1e-4,\n",
    "  dataset_dir=[\"/vol/data/flip\", \"/vol/data/move_many_random\"]\n",
    ")\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "# model_name = \"mainly_cool_gannet\"\n",
    "# model_params = None\n",
    "# train_params = None\n",
    "\n",
    "\n",
    "# model_name = petname.generate(words=3, separator='_')\n",
    "# train_on_mac(model_name, num_epochs, model_params, train_params)\n",
    "\n",
    "\n",
    "\n",
    "# model_names = ['humbly_caring_piglet', 'namely_noble_swan', 'freely_live_filly']\n",
    "model_names = []\n",
    "\n",
    "num_runs = 1\n",
    "\n",
    "fn = modal.Function.lookup(\"arc-prize\", \"train\")\n",
    "for i in range(num_runs):\n",
    "  # for model_name in model_names:\n",
    "  model_name = petname.generate(words=3, separator='_')\n",
    "  fn_call = fn.spawn(model_name, num_epochs, model_params, train_params)\n",
    "  print(\"Model name\", model_name)\n",
    "  print(fn_call.object_id)\n",
    "  model_names.append(model_name)\n",
    "\n",
    "print(model_names)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "  # \"poorly_hip_quagga\", # 8 heads\n",
    "  # \"merely_frank_collie\", # 4 heads\n",
    "  \"lively_sought_bison\", # 2 heads\n",
    "  # \"unduly_gentle_serval\", # 2 heads, 1 decoder\n",
    "  # \"purely_large_rabbit\", # 2 heads, 1 encoder, 1 decoder\n",
    "  # \"lovely_crisp_ferret\", # 4 heads, 1 encoder, 1 decoder, *2 ff\n",
    "  # \"rarely_exotic_goat\",\n",
    "  \"merely_merry_pigeon\",\n",
    "  \"nicely_eager_rodent\",\n",
    "  \"openly_fancy_oriole\", # Extra data, batch size 16\n",
    "  \"neatly_still_gannet\", # 2000 data, batch size 5\n",
    "  \"lively_useful_dragon\"\n",
    "]\n",
    "\n",
    "# model_names = [\n",
    "#   \"gladly_fast_eagle\", # 12 grid dim\n",
    "#   \"nearly_subtle_guinea\", # 30 grid dim\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# 16 dim, one layer on move_random\n",
    "model_names = [\"merely_on_cicada\", \"gently_model_tuna\", \"mainly_cool_gannet\"]\n",
    "\n",
    "# Flip 16 dim 2 layers\n",
    "model_names = [\"widely_star_tuna\", \"overly_rich_toad\", \"newly_meet_gecko\"]\n",
    "\n",
    "# Flip larger dim layers\n",
    "model_names = [\"kindly_moving_thrush\", \"fairly_good_worm\", \"rarely_new_squid\"]\n",
    "\n",
    "# Combined!\n",
    "model_names = ['humbly_caring_piglet', 'namely_noble_swan', 'freely_live_filly']\n",
    "\n",
    "epochs = {}\n",
    "\n",
    "\n",
    "# checkpoint = None\n",
    "get_model = modal.Function.lookup(\"arc-prize\", \"get_model\")\n",
    "for name in model_names:\n",
    "  checkpoint = ARCModelState(**get_model.remote(name))\n",
    "  # print(name, checkpoint.model_params)\n",
    "  print(name, len(checkpoint.epochs), checkpoint.epochs[-1])\n",
    "  epochs[name] = checkpoint.epochs\n",
    "\n",
    "visualize_epochs(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.vis import visualize_tensors\n",
    "\n",
    "\n",
    "eval_model = modal.Function.lookup(\"arc-prize\", \"evaluate_model\")\n",
    "output = eval_model.remote(\"mainly_cool_gannet\", \"/vol/data/flip\")\n",
    "for item in output[\"output\"]:\n",
    "  visualize_tensors(torch.Tensor(item[\"grids\"]).squeeze(0), torch.Tensor(item[\"output_grid\"]).squeeze(0), torch.Tensor(item[\"predictions\"]).squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.vis import visualize_output_query, visualize_tensors\n",
    "\n",
    "\n",
    "# model = ARCTransformer(d_model=d_model, num_heads=num_heads, num_layers=num_layers, d_ff=dim_feedforward, grid_dim=max_grid_size, num_colors=num_colors, num_train_pairs=max_context_pairs, dropout=dropout).to(device)\n",
    "\n",
    "model_file_name = \"models/model_75i3sirg.pth\"\n",
    "if model_file_name is not None:\n",
    "    state_dict = torch.load(model_file_name, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "eval_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, collate_fn=collate_arc_fn, num_workers=0)\n",
    "# batch = next(iter(eval_loader))\n",
    "\n",
    "# visualize_output_query(model.output_query)\n",
    "\n",
    "\n",
    "for i, batch in enumerate(eval_loader):\n",
    "    grids, grid_masks, output_grid = [item.to(device) for item in batch]\n",
    "\n",
    "    predictions = model.generate(grids, grid_masks)\n",
    "    print(predictions.shape)\n",
    "\n",
    "    visualize_tensors(grids.squeeze(0), output_grid.squeeze(0), predictions.squeeze(0))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
