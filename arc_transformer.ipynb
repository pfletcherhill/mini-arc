{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(\"data/move_right/arc-synth_move_right_training_challenges.json\", \"r\") as f:\n",
    "  tasks = json.load(f)\n",
    "  max_height = 0\n",
    "  max_width = 0\n",
    "  max_count = 0\n",
    "  for task in tasks.values():\n",
    "    count = len(task[\"train\"])\n",
    "    if count > max_count:\n",
    "      max_count = count\n",
    "    for pair in task[\"train\"]:\n",
    "      input = np.array(pair[\"input\"])\n",
    "      height, width = input.shape\n",
    "      if height > max_height:\n",
    "        max_height = height\n",
    "      if width > max_width:\n",
    "        max_width = width\n",
    "  \n",
    "  print(max_count, max_height, max_width)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.env import modal_app\n",
    "from arc_prize.model import ARCTransformer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from arc_prize.data import ARCDataset, ARCDatasetConfig, collate_arc_fn\n",
    "\n",
    "# Hyperparameters\n",
    "d_model = 128\n",
    "num_encoder_layers = 4\n",
    "num_decoder_layers = 4\n",
    "dim_feedforward = d_model * 4 # Using 4x d_model heuristic for now\n",
    "max_grid_size = 10 # 30\n",
    "num_heads = 8\n",
    "max_context_pairs = 4 # 10\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "num_colors = 10\n",
    "learning_rate = 1e-3\n",
    "dropout = 0.1\n",
    "weight_decay = 1e-5\n",
    "\n",
    "synth_arc_dataset_config = ARCDatasetConfig(max_grid_size=max_grid_size, max_train_grids=max_context_pairs, color_offset=1)\n",
    "\n",
    "# dataset_prefix = \"data/move_right/arc-synth_move_right\"\n",
    "dataset_prefix = \"data/move_random/arc-synth_move_random\"\n",
    "\n",
    "train_dataset = ARCDataset(f\"{dataset_prefix}_training_challenges.json\", f\"{dataset_prefix}_training_solutions.json\", config=synth_arc_dataset_config)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_arc_fn, num_workers=0)\n",
    "\n",
    "val_dataset = ARCDataset(f\"{dataset_prefix}_evaluation_challenges.json\", f\"{dataset_prefix}_evaluation_solutions.json\", config=synth_arc_dataset_config)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_arc_fn, num_workers=0)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ARCTransformer(d_model=d_model, num_heads=num_heads, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, d_ff=dim_feedforward, grid_dim=max_grid_size, num_colors=num_colors, num_train_pairs=max_context_pairs, dropout=dropout).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.train import train_on_modal, train_arc_transformer\n",
    "\n",
    "\n",
    "# train_arc_transformer(model, train_loader, val_loader, num_epochs, learning_rate, weight_decay)\n",
    "with modal_app.run():\n",
    "    modal_app.run(\n",
    "        train_on_modal.remote(\n",
    "            model, train_loader, val_loader, num_epochs, learning_rate, weight_decay\n",
    "        ),\n",
    "        show_progress=False,\n",
    "    )\n",
    "\n",
    "print(\"Training completed and model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.vis import visualize_tensors\n",
    "\n",
    "\n",
    "# model = ARCTransformer(d_model=d_model, num_heads=num_heads, num_layers=num_layers, d_ff=dim_feedforward, grid_dim=max_grid_size, num_colors=num_colors, num_train_pairs=max_context_pairs, dropout=dropout).to(device)\n",
    "\n",
    "model_file_name = \"models/model_4q9m0e3x.pth\"\n",
    "if model_file_name is not None:\n",
    "    state_dict = torch.load(model_file_name, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "eval_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, collate_fn=collate_arc_fn, num_workers=0)\n",
    "# batch = next(iter(eval_loader))\n",
    "\n",
    "\n",
    "\n",
    "for i, batch in enumerate(eval_loader):\n",
    "    grids, grid_masks, output_grid = [item.to(device) for item in batch]\n",
    "\n",
    "    predictions = model.generate(grids, grid_masks)\n",
    "    print(predictions.shape)\n",
    "\n",
    "    visualize_tensors(grids.squeeze(0), output_grid.squeeze(0), predictions.squeeze(0))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
