{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def positional_encoding_2d(d_model, height, width):\n",
    "    \"\"\"\n",
    "    :param d_model: dimension of the model\n",
    "    :param height: height of the positions\n",
    "    :param width: width of the positions\n",
    "    :return: d_model*height*width position matrix\n",
    "    \"\"\"\n",
    "    if d_model % 4 != 0:\n",
    "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
    "                         \"odd dimension (got dim={:d})\".format(d_model))\n",
    "    pe = torch.zeros(d_model, height, width)\n",
    "    # Each dimension use half of d_model\n",
    "    d_model = int(d_model / 2)\n",
    "    div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                         -(math.log(10000.0) / d_model))\n",
    "    pos_w = torch.arange(0., width).unsqueeze(1)\n",
    "    pos_h = torch.arange(0., height).unsqueeze(1)\n",
    "    pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
    "    pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
    "    pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    pe[d_model + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameOfLifeTransformer(nn.Module):\n",
    "    def __init__(self, grid_size, d_model, nhead, num_layers):\n",
    "        super(GameOfLifeTransformer, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = nn.Linear(1, d_model)\n",
    "        self.pos_encoder = positional_encoding_2d(d_model, grid_size, grid_size)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=2048)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        self.output_layer = nn.Linear(d_model, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: (batch_size, num_frames, grid_size, grid_size)\n",
    "        batch_size, num_frames, height, width = src.shape\n",
    "        \n",
    "        # Reshape and embed\n",
    "        src = src.reshape(batch_size * num_frames, height * width, 1)\n",
    "        src = self.embedding(src)  # (batch_size * num_frames, grid_size*grid_size, d_model)\n",
    "        \n",
    "        # Reshape positional encoding to match src\n",
    "        pos_encoding = self.pos_encoder.view(1, height * width, self.d_model)\n",
    "        pos_encoding = pos_encoding.repeat(batch_size * num_frames, 1, 1)\n",
    "        \n",
    "        src = src + pos_encoding.to(src.device)\n",
    "        \n",
    "        src = src.permute(1, 0, 2)  # (grid_size*grid_size, batch_size * num_frames, d_model)\n",
    "        \n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.output_layer(output)\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output.permute(1, 2, 0).reshape(batch_size, num_frames, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_game_of_life_dataset(num_samples, grid_size, num_steps):\n",
    "    def update(frame):\n",
    "        # Game of Life update rules\n",
    "        n = sum([np.roll(np.roll(frame, i, 0), j, 1)\n",
    "                 for i in (-1, 0, 1) for j in (-1, 0, 1)\n",
    "                 if (i != 0 or j != 0)])\n",
    "        return ((n == 3) | ((frame == 1) & (n == 2))).astype(int)\n",
    "\n",
    "    dataset = []\n",
    "    for _ in range(num_samples):\n",
    "        # Random initial state\n",
    "        initial_state = np.random.choice([0, 1], size=(grid_size, grid_size))\n",
    "        sequence = [initial_state]\n",
    "        for _ in range(num_steps - 1):\n",
    "            next_state = update(sequence[-1])\n",
    "            sequence.append(next_state)\n",
    "        dataset.append(np.array(sequence))\n",
    "    \n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 1/50, Loss: 17.9451\n",
      "Epoch 2/50, Loss: 15.4759\n",
      "Epoch 3/50, Loss: 15.0648\n",
      "Epoch 4/50, Loss: 14.9679\n",
      "Epoch 5/50, Loss: 14.9376\n",
      "Epoch 6/50, Loss: 14.9256\n",
      "Epoch 7/50, Loss: 14.9219\n",
      "Epoch 8/50, Loss: 14.9182\n",
      "Epoch 9/50, Loss: 14.9151\n",
      "Epoch 10/50, Loss: 14.9101\n",
      "Epoch 11/50, Loss: 14.9101\n",
      "Epoch 12/50, Loss: 14.9091\n",
      "Epoch 13/50, Loss: 14.9091\n",
      "Epoch 14/50, Loss: 14.9070\n",
      "Epoch 15/50, Loss: 14.9050\n",
      "Epoch 16/50, Loss: 14.9040\n",
      "Epoch 17/50, Loss: 14.9049\n",
      "Epoch 18/50, Loss: 14.9052\n",
      "Epoch 19/50, Loss: 14.9034\n",
      "Epoch 20/50, Loss: 14.9037\n",
      "Epoch 21/50, Loss: 14.9037\n",
      "Epoch 22/50, Loss: 14.9043\n",
      "Epoch 23/50, Loss: 14.9032\n",
      "Epoch 24/50, Loss: 14.9033\n",
      "Epoch 25/50, Loss: 14.9018\n",
      "Epoch 26/50, Loss: 14.9016\n",
      "Epoch 27/50, Loss: 14.9009\n",
      "Epoch 28/50, Loss: 14.9007\n",
      "Epoch 29/50, Loss: 14.9003\n",
      "Epoch 30/50, Loss: 14.9014\n",
      "Epoch 31/50, Loss: 14.9013\n",
      "Epoch 32/50, Loss: 14.8993\n",
      "Epoch 33/50, Loss: 14.8990\n",
      "Epoch 34/50, Loss: 14.8964\n",
      "Epoch 35/50, Loss: 14.8967\n",
      "Epoch 36/50, Loss: 14.8968\n",
      "Epoch 37/50, Loss: 14.8949\n",
      "Epoch 38/50, Loss: 14.8937\n",
      "Epoch 39/50, Loss: 14.8910\n",
      "Epoch 40/50, Loss: 14.8869\n",
      "Epoch 41/50, Loss: 14.8597\n",
      "Epoch 42/50, Loss: 14.8303\n",
      "Epoch 43/50, Loss: 14.8050\n",
      "Epoch 44/50, Loss: 14.7792\n",
      "Epoch 45/50, Loss: 14.7424\n",
      "Epoch 46/50, Loss: 14.6960\n",
      "Epoch 47/50, Loss: 14.6648\n",
      "Epoch 48/50, Loss: 14.6334\n",
      "Epoch 49/50, Loss: 14.5997\n",
      "Epoch 50/50, Loss: 14.5594\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters\n",
    "grid_size = 10\n",
    "d_model = 64\n",
    "nhead = 4\n",
    "num_layers = 3\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_game_of_life_dataset(1000, grid_size, 10)\n",
    "dataset = torch.FloatTensor(dataset)\n",
    "\n",
    "# Create model\n",
    "model = GameOfLifeTransformer(grid_size, d_model, nhead, num_layers)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = dataset[i:i+batch_size]\n",
    "        inputs = batch[:, :-1]  # All frames except the last\n",
    "        targets = batch[:, 1:]  # All frames except the first\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"game_of_life_transformer.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
