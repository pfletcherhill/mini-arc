{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from jax import Array\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "\n",
    "from arc_prize.vis import COLORS\n",
    "\n",
    "def visualize_embeddings(embeddings: Array, num_grids: int):\n",
    "    \"\"\"\n",
    "    Visualize embeddings using t-SNE or PCA.\n",
    "    \n",
    "    :param embeddings: torch.Tensor of shape (n_samples, embedding_dim)\n",
    "    :param labels: list of labels for each embedding (optional)\n",
    "    :param method: 'tsne' or 'pca'\n",
    "    \"\"\"\n",
    "    embeddings_np = embeddings\n",
    "    \n",
    "    \n",
    "    tsne_reducer = TSNE(n_components=2, random_state=42)\n",
    "    pca_reducer = PCA(n_components=2)\n",
    "    \n",
    "    reduced_tsne_embeddings = tsne_reducer.fit_transform(embeddings_np)\n",
    "    reduced_pca_embeddings = pca_reducer.fit_transform(embeddings_np)\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(COLORS)\n",
    "    per_grid = len(reduced_tsne_embeddings) // num_grids\n",
    "    grid_indices = torch.arange(num_grids).repeat_interleave(per_grid)\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "    scatter1 = ax1.scatter(reduced_tsne_embeddings[:, 0], reduced_tsne_embeddings[:, 1], c=grid_indices)\n",
    "    plt.colorbar(scatter1, ax=ax1)\n",
    "    ax1.set_title(\"Embeddings with TSNE by grid\")\n",
    "\n",
    "    scatter2 = ax2.scatter(reduced_pca_embeddings[:, 0], reduced_pca_embeddings[:, 1], c=grid_indices)\n",
    "    plt.colorbar(scatter2, ax=ax2)\n",
    "    ax2.set_title(\"Embeddings with PCA by grid\")\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.flax.models import create_arc_fixed_positional_encoding\n",
    "\n",
    "\n",
    "enc = create_arc_fixed_positional_encoding(32, 10, 4)\n",
    "\n",
    "print(enc.shape)\n",
    "\n",
    "visualize_embeddings(enc.reshape(-1, 32), num_grids=9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.flax.models import ARCTransformerEncoderDecoderParams\n",
    "from arc_prize.flax.train import TrainParams, train_and_evaluate_local\n",
    "\n",
    "model_params = ARCTransformerEncoderDecoderParams(\n",
    "  grid_dim=12,\n",
    "  num_train_pairs=4,\n",
    "  num_colors=10,\n",
    "  num_encoder_layers=2,\n",
    "  num_decoder_layers=2,\n",
    "  num_heads=2,\n",
    "  d_model=16,\n",
    "  d_ff=16*4,\n",
    "  dropout=0.1\n",
    ")\n",
    "\n",
    "train_params = TrainParams(\n",
    "  batch_size=20,\n",
    "  learning_rate=1e-4,\n",
    "  weight_decay=1e-4,\n",
    "  warmup_steps=5,\n",
    "  train_steps_per_epoch=10,\n",
    "  eval_steps_per_epoch=5,\n",
    "  dataset_dirs=[\"/Users/pfh/work/arc-data/flip\"],\n",
    "  loss_class_weights={0: 0.2}\n",
    ")\n",
    "\n",
    "model_dir = \"/Users/pfh/work/arc-models/flax-2\"\n",
    "num_epochs = 100\n",
    "\n",
    "train_and_evaluate_local(model_dir, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.flax.models import ARCTransformerEncoderDecoderParams\n",
    "from arc_prize.flax.train import TrainParams\n",
    "import modal\n",
    "import petname\n",
    "\n",
    "model_params = ARCTransformerEncoderDecoderParams(\n",
    "  grid_dim=12,\n",
    "  num_train_pairs=4,\n",
    "  num_colors=10,\n",
    "  num_encoder_layers=2,\n",
    "  num_decoder_layers=2,\n",
    "  num_heads=4,\n",
    "  d_model=64,\n",
    "  d_ff=64*4,\n",
    "  dropout=0.1\n",
    ")\n",
    "\n",
    "train_params = TrainParams(\n",
    "  batch_size=20,\n",
    "  learning_rate=1e-4,\n",
    "  weight_decay=1e-4,\n",
    "  warmup_steps=50,\n",
    "  train_steps_per_epoch=30,\n",
    "  eval_steps_per_epoch=5,\n",
    "  dataset_dirs=[\"/vol/data/flip\"],\n",
    "  loss_class_weights={0: 0.2}\n",
    ")\n",
    "\n",
    "model_name = petname.generate(words=3, separator='_')\n",
    "model_dir = f\"/vol/models/{model_name}\"\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "fn = modal.Function.lookup(\"arc-jax\", \"train\")\n",
    "fn_call = fn.spawn(model_dir, train_params, model_params, num_epochs)\n",
    "print(\"Model name\", model_name, fn_call.object_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nnx\n",
    "\n",
    "rng1 = nnx.Rngs(0, params=1)\n",
    "rng2 = nnx.Rngs(0)\n",
    "print(rng1, rng2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
