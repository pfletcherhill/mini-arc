{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from jax import Array\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "\n",
    "from arc_prize.vis import COLORS\n",
    "\n",
    "def visualize_embeddings(embeddings: Array, num_grids: int):\n",
    "    \"\"\"\n",
    "    Visualize embeddings using t-SNE or PCA.\n",
    "    \n",
    "    :param embeddings: torch.Tensor of shape (n_samples, embedding_dim)\n",
    "    :param labels: list of labels for each embedding (optional)\n",
    "    :param method: 'tsne' or 'pca'\n",
    "    \"\"\"\n",
    "    embeddings_np = embeddings\n",
    "    \n",
    "    \n",
    "    tsne_reducer = TSNE(n_components=2, random_state=42)\n",
    "    pca_reducer = PCA(n_components=2)\n",
    "    \n",
    "    reduced_tsne_embeddings = tsne_reducer.fit_transform(embeddings_np)\n",
    "    reduced_pca_embeddings = pca_reducer.fit_transform(embeddings_np)\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(COLORS)\n",
    "    per_grid = len(reduced_tsne_embeddings) // num_grids\n",
    "    grid_indices = torch.arange(num_grids).repeat_interleave(per_grid)\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "    scatter1 = ax1.scatter(reduced_tsne_embeddings[:, 0], reduced_tsne_embeddings[:, 1], c=grid_indices)\n",
    "    plt.colorbar(scatter1, ax=ax1)\n",
    "    ax1.set_title(\"Embeddings with TSNE by grid\")\n",
    "\n",
    "    scatter2 = ax2.scatter(reduced_pca_embeddings[:, 0], reduced_pca_embeddings[:, 1], c=grid_indices)\n",
    "    plt.colorbar(scatter2, ax=ax2)\n",
    "    ax2.set_title(\"Embeddings with PCA by grid\")\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc_prize.flax.models import create_arc_fixed_positional_encoding\n",
    "\n",
    "\n",
    "enc = create_arc_fixed_positional_encoding(32, 10, 4)\n",
    "\n",
    "print(enc.shape)\n",
    "\n",
    "visualize_embeddings(enc.reshape(-1, 32), num_grids=9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest step 14\n",
      "GPU devices [CpuDevice(id=0)]\n",
      "Starting training run with dataset of 1000 training items and 200 evaluation items: /Users/pfh/work/arc-data/flip\n",
      "Using batch size of 20\n",
      "Starting epoch 15/20\n",
      "Train loss (completed in 10.95s): 1.4297, accuracy: 0.6848\n",
      "Eval loss (competed in 2.18s): 1.4241, accuracy: 0.6801\n",
      "Starting epoch 16/20\n",
      "Train loss (completed in 6.52s): 1.4182, accuracy: 0.6839\n",
      "Eval loss (competed in 1.57s): 1.4129, accuracy: 0.6852\n",
      "Starting epoch 17/20\n",
      "Train loss (completed in 6.31s): 1.4027, accuracy: 0.6879\n",
      "Eval loss (competed in 1.56s): 1.3867, accuracy: 0.6881\n",
      "Starting epoch 18/20\n",
      "Train loss (completed in 6.45s): 1.4113, accuracy: 0.6838\n",
      "Eval loss (competed in 1.60s): 1.3753, accuracy: 0.6908\n",
      "Starting epoch 19/20\n",
      "Train loss (completed in 6.52s): 1.4005, accuracy: 0.6852\n",
      "Eval loss (competed in 1.87s): 1.3624, accuracy: 0.6950\n",
      "Starting epoch 20/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/pfh/work/arc-models/flax-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrain_and_evaluate_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/arc-prize/arc_prize/flax/train.py:452\u001b[0m, in \u001b[0;36mtrain_and_evaluate_local\u001b[0;34m(model_dir, num_epochs, model_params, train_params, force_restart)\u001b[0m\n\u001b[1;32m    446\u001b[0m model_params, train_params \u001b[38;5;241m=\u001b[39m get_config_params(\n\u001b[1;32m    447\u001b[0m     model_dir, model_params, train_params\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m save_config_params(model_dir, model_params, train_params)\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_restart\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/arc-prize/arc_prize/flax/train.py:304\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model_dir, model_params, train_params, num_epochs, force_restart)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_data_loader:\n\u001b[1;32m    301\u001b[0m     model_state, opt_state, loss, accuracy \u001b[38;5;241m=\u001b[39m train_step(\n\u001b[1;32m    302\u001b[0m         graphdef, model_state, optimizer, opt_state, batch, class_weights\n\u001b[1;32m    303\u001b[0m     )\n\u001b[0;32m--> 304\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     train_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accuracy\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    306\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data_loader)\n",
      "File \u001b[0;32m~/work/arc-prize/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:209\u001b[0m, in \u001b[0;36m_item\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_item\u001b[39m(\u001b[38;5;28mself\u001b[39m: Array, \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mcomplex\u001b[39m:\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Copy an element of an array to a standard Python scalar and return it.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m   arr \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcrete_or_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThis occurred in the item() method of jax.Array\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, dtypes\u001b[38;5;241m.\u001b[39mextended):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo Python scalar type for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/arc-prize/.venv/lib/python3.12/site-packages/jax/_src/core.py:1566\u001b[0m, in \u001b[0;36mconcrete_or_error\u001b[0;34m(force, val, context)\u001b[0m\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConcretizationTypeError(val, context)\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1566\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from arc_prize.flax.models import ARCTransformerEncoderDecoderParams\n",
    "from arc_prize.flax.train import TrainParams, train_and_evaluate_local\n",
    "\n",
    "model_params = ARCTransformerEncoderDecoderParams(\n",
    "  grid_dim=10,\n",
    "  num_train_pairs=4,\n",
    "  num_colors=10,\n",
    "  num_encoder_layers=2,\n",
    "  num_decoder_layers=2,\n",
    "  num_heads=2,\n",
    "  d_model=16,\n",
    "  d_ff=16*4,\n",
    "  dropout=0.1\n",
    ")\n",
    "\n",
    "train_params = TrainParams(\n",
    "  batch_size=20,\n",
    "  learning_rate=1e-4,\n",
    "  weight_decay=1e-4,\n",
    "  warmup_steps=5,\n",
    "  train_steps_per_epoch=10,\n",
    "  eval_steps_per_epoch=5,\n",
    "  dataset_dirs=[\"/Users/pfh/work/arc-data/flip\"],\n",
    "  loss_class_weights={0: 0.2}\n",
    ")\n",
    "\n",
    "model_dir = \"/Users/pfh/work/arc-models/flax-4\"\n",
    "num_epochs = 6\n",
    "\n",
    "train_and_evaluate_local(model_dir, num_epochs, model_params, train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:CheckpointManagerOptions.read_only=True, setting save_interval_steps=0.\n",
      "WARNING:absl:CheckpointManagerOptions.read_only=True, setting create=False.\n",
      "WARNING:absl:Given directory is read only=/Users/pfh/work/arc-models/flax-2/checkpoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU devices [CpuDevice(id=0)]\n",
      "latest step 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pfh/work/arc-prize/.venv/lib/python3.12/site-packages/orbax/checkpoint/type_handlers.py:1372: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphdef None\n",
      "keys dict_keys(['graphdef', 'opt_state', 'other_state', 'params', 'step'])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'flat_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      7\u001b[0m model_params, _ \u001b[38;5;241m=\u001b[39m get_config_params(model_dir)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/arc-prize/arc_prize/flax/train.py:327\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model_dir, model_params, dataset_dir, num_steps)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m    326\u001b[0m     grids, masks, targets \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 327\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestored_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgraphdef\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestored_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestored_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mother_state\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m, logits, predictions)\n",
      "File \u001b[0;32m~/work/arc-prize/arc_prize/flax/train.py:105\u001b[0m, in \u001b[0;36mpredict_step\u001b[0;34m(graphdef, params, other_state, grids, masks)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_step\u001b[39m(\n\u001b[1;32m     99\u001b[0m     graphdef: nnx\u001b[38;5;241m.\u001b[39mGraphDef,\n\u001b[1;32m    100\u001b[0m     params: nnx\u001b[38;5;241m.\u001b[39mGraphState,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m     masks: jnp\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m    104\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m jnp\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 105\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mnnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphdef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, model)\n\u001b[1;32m    107\u001b[0m     model\u001b[38;5;241m.\u001b[39meval(decode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/work/arc-prize/.venv/lib/python3.12/site-packages/flax/nnx/nnx/graph.py:1413\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(graphdef, state, *states)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   1373\u001b[0m   graphdef: GraphDef[A],\n\u001b[1;32m   1374\u001b[0m   state: GraphState,\n\u001b[1;32m   1375\u001b[0m   \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   1376\u001b[0m   \u001b[38;5;241m*\u001b[39mstates: GraphState,\n\u001b[1;32m   1377\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m A:\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"The inverse of :func:`split`.\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \n\u001b[1;32m   1380\u001b[0m \u001b[38;5;124;03m  ``merge`` takes a :class:`GraphDef` and one or more :class:`State`'s and creates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;124;03m    The merged :class:`Module`.\u001b[39;00m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1413\u001b[0m   state \u001b[38;5;241m=\u001b[39m \u001b[43mGraphState\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m   node \u001b[38;5;241m=\u001b[39m unflatten(graphdef, state)\n\u001b[1;32m   1415\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/work/arc-prize/.venv/lib/python3.12/site-packages/flax/nnx/nnx/state.py:340\u001b[0m, in \u001b[0;36mState.merge\u001b[0;34m(state, *states)\u001b[0m\n\u001b[1;32m    337\u001b[0m new_state: FlatState[V] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m states:\n\u001b[0;32m--> 340\u001b[0m   new_state\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_state\u001b[49m())  \u001b[38;5;66;03m# type: ignore[attribute-error] # pytype is wrong here\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m State\u001b[38;5;241m.\u001b[39mfrom_flat_path(new_state)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'flat_state'"
     ]
    }
   ],
   "source": [
    "from arc_prize.flax.train import get_config_params, predict\n",
    "\n",
    "model_dir = \"/Users/pfh/work/arc-models/flax-2\"\n",
    "dataset_dir = \"/Users/pfh/work/arc-data/flip\"\n",
    "num_steps = 10\n",
    "\n",
    "model_params, _ = get_config_params(model_dir)\n",
    "\n",
    "predict(model_dir, model_params, dataset_dir, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name mainly_neat_mite fc-01JAC2TTXC4K6AAYCNA2VFJ1KV\n"
     ]
    }
   ],
   "source": [
    "from arc_prize.flax.models import ARCTransformerEncoderDecoderParams\n",
    "from arc_prize.flax.train import TrainParams\n",
    "import modal\n",
    "import petname\n",
    "\n",
    "model_params = ARCTransformerEncoderDecoderParams(\n",
    "  grid_dim=20,\n",
    "  num_train_pairs=4,\n",
    "  num_colors=10,\n",
    "  num_encoder_layers=6,\n",
    "  num_decoder_layers=6,\n",
    "  num_heads=16,\n",
    "  d_model=256,\n",
    "  d_ff=256*4,\n",
    "  dropout=0.1\n",
    ")\n",
    "\n",
    "train_params = TrainParams(\n",
    "  batch_size=32,\n",
    "  learning_rate=1e-4,\n",
    "  weight_decay=1e-4,\n",
    "  warmup_steps=3,\n",
    "  train_steps_per_epoch=300,\n",
    "  eval_steps_per_epoch=50,\n",
    "  dataset_dirs=[\"/vol/data/html_dim_20_20240925\"],\n",
    "  loss_class_weights={0: 0.2}\n",
    ")\n",
    "\n",
    "model_name = petname.generate(words=3, separator='_')\n",
    "model_dir = f\"/vol/models/{model_name}\"\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "fn = modal.Function.lookup(\"arc-jax\", \"train\")\n",
    "fn_call = fn.spawn(model_dir, model_params, train_params, num_epochs)\n",
    "print(\"Model name\", model_name, fn_call.object_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nnx\n",
    "\n",
    "rng1 = nnx.Rngs(0, params=1)\n",
    "rng2 = nnx.Rngs(0)\n",
    "print(rng1, rng2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
